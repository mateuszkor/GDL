{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dde5ec8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colab setup (safe to skip locally)\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "ALLOW_DOWNLOADS = IN_COLAB  # set True locally if you want to download datasets\n",
        "\n",
        "if IN_COLAB:\n",
        "    import subprocess\n",
        "    import torch\n",
        "\n",
        "    # Install SciPy (needed by Planetoid) and PyG dependencies\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'scipy'])\n",
        "\n",
        "    torch_ver = torch.__version__.split('+')[0]\n",
        "    cuda_ver = torch.version.cuda or 'cpu'\n",
        "    pyg_wheel = f\"https://data.pyg.org/whl/torch-{torch_ver}+{cuda_ver}.html\"\n",
        "\n",
        "    subprocess.check_call([\n",
        "        sys.executable, '-m', 'pip', 'install', '-q',\n",
        "        'torch-scatter', 'torch-sparse', 'torch-cluster', 'torch-spline-conv',\n",
        "        '-f', pyg_wheel\n",
        "    ])\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'torch-geometric'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb9df40",
      "metadata": {},
      "source": [
        "# Experiment: GNN Failure Risk Audit\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mateuszkor/GDL/blob/main/output/jupyter-notebook/gnn-failure-risk-audit.ipynb)\n",
        "\n",
        "Objective:\n",
        "- Test whether graph-structural signals predict GNN failure (generalisation error).\n",
        "- Compare MLP vs GCN vs GraphSAGE vs GAT across graph families.\n",
        "\n",
        "Success criteria:\n",
        "- Produce performance vs homophily plots and a risk-structure correlation table.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58103deb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: imports and reproducibility\n",
        "from __future__ import annotations\n",
        "\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Ensure matplotlib can write cache (use /tmp in restricted envs)\n",
        "os.environ.setdefault('MPLCONFIGDIR', '/tmp')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d47efd3c",
      "metadata": {},
      "source": [
        "## Plan\n",
        "\n",
        "Hypothesis:\n",
        "- GNN generalisation degrades as alignment between graph structure and labels weakens.\n",
        "\n",
        "Variables to sweep:\n",
        "- Homophily/heterophily (via SBM parameters)\n",
        "- Graph size / degree regime\n",
        "- Eigenvalue structure (approx. via SBM settings)\n",
        "\n",
        "Metrics:\n",
        "- Accuracy (train/val/test)\n",
        "- Generalisation gap\n",
        "- Correlation with structural risk signals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fefe822",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration (small sweep)\n",
        "CONFIG = {\n",
        "    \"num_graphs_per_setting\": 3,\n",
        "    \"num_nodes\": [200, 400],\n",
        "    \"feature_dim\": 16,\n",
        "    \"num_classes\": 2,\n",
        "    \"sbm_settings\": [\n",
        "        # (p_in, p_out) controls homophily\n",
        "        (0.10, 0.01),\n",
        "        (0.07, 0.03),\n",
        "        (0.03, 0.05),\n",
        "    ],\n",
        "    \"train_ratio\": 0.6,\n",
        "    \"val_ratio\": 0.2,\n",
        "    \"epochs\": 30,\n",
        "    \"lr\": 1e-3,\n",
        "    \"hidden_dim\": 32,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e5b035e",
      "metadata": {},
      "source": [
        "## Data: Graph Families\n",
        "We generate synthetic SBM graphs to control homophily/heterophily. Labels are tied to SBM communities, and we compute structural signals per graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2e2022",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Synthetic graph generation (SBM)\n",
        "\n",
        "def generate_sbm_graph(num_nodes, num_classes, p_in, p_out, feature_dim, seed):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    sizes = [num_nodes // num_classes for _ in range(num_classes)]\n",
        "    sizes[0] += num_nodes - sum(sizes)\n",
        "    probs = [[p_in if i == j else p_out for j in range(num_classes)] for i in range(num_classes)]\n",
        "\n",
        "    G = nx.stochastic_block_model(sizes, probs, seed=seed)\n",
        "    labels = []\n",
        "    for c, size in enumerate(sizes):\n",
        "        labels.extend([c] * size)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Features: random + weak label signal (can be adjusted later)\n",
        "    features = rng.normal(size=(num_nodes, feature_dim)).astype(np.float32)\n",
        "    features += 0.1 * rng.normal(size=(num_nodes, feature_dim)).astype(np.float32) * labels[:, None]\n",
        "\n",
        "    data = from_networkx(G)\n",
        "    data.x = torch.tensor(features, dtype=torch.float)\n",
        "    data.y = torch.tensor(labels, dtype=torch.long)\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96effe9",
      "metadata": {},
      "source": [
        "## Structural Risk Signals\n",
        "We compute lightweight proxies: homophily ratio and spectral gap (approx.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50b10adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Structural signals\n",
        "\n",
        "def homophily_ratio(edge_index, labels):\n",
        "    src, dst = edge_index\n",
        "    same = (labels[src] == labels[dst]).float()\n",
        "    return same.mean().item() if same.numel() > 0 else 0.0\n",
        "\n",
        "\n",
        "def spectral_gap_approx(data, k=6):\n",
        "    # Placeholder: use normalized Laplacian eigenvalues (small k)\n",
        "    # TODO: refine if needed\n",
        "    import torch_geometric.utils as tg_utils\n",
        "    L = tg_utils.get_laplacian(data.edge_index, normalization='sym')\n",
        "    # This returns edge_index, edge_weight of Laplacian; converting to dense for small graphs only\n",
        "    n = data.num_nodes\n",
        "    dense = torch.zeros((n, n))\n",
        "    dense[L[0][0], L[0][1]] = L[1]\n",
        "    # Compute a few smallest eigenvalues\n",
        "    vals = torch.linalg.eigvalsh(dense).cpu().numpy()\n",
        "    vals = np.sort(vals)\n",
        "    if len(vals) >= 2:\n",
        "        return float(vals[1] - vals[0])\n",
        "    return 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f279d989",
      "metadata": {},
      "source": [
        "## Models\n",
        "Baseline MLP vs GCN / GraphSAGE / GAT.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1160f818",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index=None):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim, heads=4):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_dim, hidden_dim, heads=heads, concat=True)\n",
        "        self.conv2 = GATConv(hidden_dim * heads, out_dim, heads=1, concat=False)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "547e526d",
      "metadata": {},
      "source": [
        "## Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b25713",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/val/test split\n",
        "\n",
        "def split_masks(num_nodes, train_ratio=0.6, val_ratio=0.2, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = rng.permutation(num_nodes)\n",
        "    n_train = int(train_ratio * num_nodes)\n",
        "    n_val = int(val_ratio * num_nodes)\n",
        "    train_idx = idx[:n_train]\n",
        "    val_idx = idx[n_train:n_train + n_val]\n",
        "    test_idx = idx[n_train + n_val:]\n",
        "\n",
        "    mask = lambda ids: torch.tensor(ids, dtype=torch.long)\n",
        "    return mask(train_idx), mask(val_idx), mask(test_idx)\n",
        "\n",
        "\n",
        "def train_epoch(model, data, train_idx, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[train_idx], data.y[train_idx])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def eval_acc(model, data, idx):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        pred = out.argmax(dim=-1)\n",
        "        acc = (pred[idx] == data.y[idx]).float().mean().item()\n",
        "    return acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f4b17d",
      "metadata": {},
      "source": [
        "## Experiment Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77477113",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run over graph families and models, collect results\n",
        "\n",
        "results = []\n",
        "\n",
        "MODEL_FACTORIES = {\n",
        "    \"MLP\": lambda in_dim, hidden_dim, out_dim: MLP(in_dim, hidden_dim, out_dim),\n",
        "    \"GCN\": lambda in_dim, hidden_dim, out_dim: GCN(in_dim, hidden_dim, out_dim),\n",
        "    \"GraphSAGE\": lambda in_dim, hidden_dim, out_dim: GraphSAGE(in_dim, hidden_dim, out_dim),\n",
        "    \"GAT\": lambda in_dim, hidden_dim, out_dim: GAT(in_dim, hidden_dim, out_dim),\n",
        "}\n",
        "\n",
        "for num_nodes in CONFIG[\"num_nodes\"]:\n",
        "    for p_in, p_out in CONFIG[\"sbm_settings\"]:\n",
        "        for i in range(CONFIG[\"num_graphs_per_setting\"]):\n",
        "            seed = SEED + i + int(p_in * 1000)\n",
        "            data = generate_sbm_graph(\n",
        "                num_nodes=num_nodes,\n",
        "                num_classes=CONFIG[\"num_classes\"],\n",
        "                p_in=p_in,\n",
        "                p_out=p_out,\n",
        "                feature_dim=CONFIG[\"feature_dim\"],\n",
        "                seed=seed,\n",
        "            )\n",
        "            train_idx, val_idx, test_idx = split_masks(\n",
        "                data.num_nodes,\n",
        "                CONFIG[\"train_ratio\"],\n",
        "                CONFIG[\"val_ratio\"],\n",
        "                seed=seed,\n",
        "            )\n",
        "\n",
        "            h_ratio = homophily_ratio(data.edge_index, data.y)\n",
        "            s_gap = spectral_gap_approx(data)\n",
        "\n",
        "            for model_name, factory in MODEL_FACTORIES.items():\n",
        "                model = factory(data.num_features, CONFIG[\"hidden_dim\"], CONFIG[\"num_classes\"])\n",
        "                optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
        "                for _ in range(CONFIG[\"epochs\"]):\n",
        "                    train_epoch(model, data, train_idx, optimizer)\n",
        "\n",
        "                train_acc = eval_acc(model, data, train_idx)\n",
        "                val_acc = eval_acc(model, data, val_idx)\n",
        "                test_acc = eval_acc(model, data, test_idx)\n",
        "\n",
        "                results.append({\n",
        "                    \"num_nodes\": num_nodes,\n",
        "                    \"p_in\": p_in,\n",
        "                    \"p_out\": p_out,\n",
        "                    \"graph_seed\": seed,\n",
        "                    \"model\": model_name,\n",
        "                    \"train_acc\": train_acc,\n",
        "                    \"val_acc\": val_acc,\n",
        "                    \"test_acc\": test_acc,\n",
        "                    \"gen_gap\": train_acc - test_acc,\n",
        "                    \"homophily\": h_ratio,\n",
        "                    \"spectral_gap\": s_gap,\n",
        "                })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "878934b6",
      "metadata": {},
      "source": [
        "## Results (Planned)\n",
        "- Plot accuracy vs homophily\n",
        "- Correlate risk signals with generalisation gap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2497e9e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze and plot\n",
        "from pathlib import Path\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(df.head())\n",
        "\n",
        "out_path = \"output/experiments/gnn_failure_experiment_log.csv\"\n",
        "Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "df.to_csv(out_path, index=False)\n",
        "print(f\"Wrote {out_path}\")\n",
        "\n",
        "# Plot: homophily vs test accuracy by model\n",
        "plt.figure(figsize=(6, 4))\n",
        "for model, g in df.groupby(\"model\"):\n",
        "    plt.scatter(g[\"homophily\"], g[\"test_acc\"], label=model, alpha=0.7)\n",
        "plt.xlabel(\"Homophily ratio\")\n",
        "plt.ylabel(\"Test accuracy\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"output/experiments/homophily_vs_test_acc.png\", dpi=150)\n",
        "\n",
        "# Plot: homophily vs generalization gap\n",
        "plt.figure(figsize=(6, 4))\n",
        "for model, g in df.groupby(\"model\"):\n",
        "    plt.scatter(g[\"homophily\"], g[\"gen_gap\"], label=model, alpha=0.7)\n",
        "plt.xlabel(\"Homophily ratio\")\n",
        "plt.ylabel(\"Generalization gap (train - test)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"output/experiments/homophily_vs_gen_gap.png\", dpi=150)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eeefa9d",
      "metadata": {},
      "source": [
        "## Real Datasets (Planetoid)\n",
        "We repeat the risk analysis on two real-world citation datasets: Cora and CiteSeer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdece1e3",
      "metadata": {},
      "source": [
        "> Note: Planetoid datasets require local files. If Cora/CiteSeer are not already present under `output/datasets/Planetoid`,\n",
        "> the cells will skip them. Download the datasets locally and rerun to include real-data results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26041d4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import to_undirected\n",
        "\n",
        "REAL_DATASETS = [\"Cora\", \"CiteSeer\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bbc3c60",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Real dataset helpers\n",
        "from pathlib import Path\n",
        "\n",
        "def load_planetoid(name, root=\"output/datasets/Planetoid\"):\n",
        "    root_path = Path(root) / name\n",
        "    raw_dir = root_path / \"raw\"\n",
        "    processed_dir = root_path / \"processed\"\n",
        "\n",
        "    # If not allowed to download and files are missing, skip.\n",
        "    if not ALLOW_DOWNLOADS and not (raw_dir.exists() or processed_dir.exists()):\n",
        "        print(\n",
        "            f\"[SKIP] {name} not found locally at {root_path}. \"\n",
        "            \"Download the Planetoid datasets first (Cora/CiteSeer) and rerun.\"\n",
        "        )\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        dataset = Planetoid(root=root, name=name)\n",
        "        data = dataset[0]\n",
        "        data.edge_index = to_undirected(data.edge_index)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"[SKIP] Failed to load {name}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def spectral_gap_sparse(data, k=2):\n",
        "    try:\n",
        "        edge_index, edge_weight = get_laplacian(data.edge_index, normalization='sym')\n",
        "        n = data.num_nodes\n",
        "        L = torch.sparse_coo_tensor(edge_index, edge_weight, (n, n))\n",
        "        vals, _ = torch.lobpcg(L, k=k, largest=False)\n",
        "        vals = vals.cpu().numpy()\n",
        "        vals.sort()\n",
        "        if len(vals) >= 2:\n",
        "            return float(vals[1] - vals[0])\n",
        "    except Exception:\n",
        "        pass\n",
        "    return float('nan')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61df49f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run on real datasets\n",
        "real_results = []\n",
        "\n",
        "for name in REAL_DATASETS:\n",
        "    data = load_planetoid(name)\n",
        "    if data is None:\n",
        "        continue\n",
        "\n",
        "    data = data.to(DEVICE)\n",
        "\n",
        "    # Use standard Planetoid splits\n",
        "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1)\n",
        "    val_idx = data.val_mask.nonzero(as_tuple=False).view(-1)\n",
        "    test_idx = data.test_mask.nonzero(as_tuple=False).view(-1)\n",
        "\n",
        "    h_ratio = homophily_ratio(data.edge_index, data.y)\n",
        "    s_gap = spectral_gap_sparse(data)\n",
        "\n",
        "    for model_name, factory in MODEL_FACTORIES.items():\n",
        "        model = factory(data.num_features, CONFIG[\"hidden_dim\"], int(data.y.max().item()) + 1).to(DEVICE)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
        "        for _ in range(CONFIG[\"epochs\"]):\n",
        "            train_epoch(model, data, train_idx, optimizer)\n",
        "\n",
        "        train_acc = eval_acc(model, data, train_idx)\n",
        "        val_acc = eval_acc(model, data, val_idx)\n",
        "        test_acc = eval_acc(model, data, test_idx)\n",
        "\n",
        "        real_results.append({\n",
        "            \"dataset\": name,\n",
        "            \"model\": model_name,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_acc\": val_acc,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"gen_gap\": train_acc - test_acc,\n",
        "            \"homophily\": h_ratio,\n",
        "            \"spectral_gap\": s_gap,\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c72955",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af7043c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save and plot real dataset results\n",
        "from pathlib import Path\n",
        "real_df = pd.DataFrame(real_results)\n",
        "real_out = \"output/experiments/gnn_failure_real_datasets.csv\"\n",
        "Path(real_out).parent.mkdir(parents=True, exist_ok=True)\n",
        "real_df.to_csv(real_out, index=False)\n",
        "print(f\"Wrote {real_out}\")\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "for model, g in real_df.groupby(\"model\"):\n",
        "    plt.scatter(g[\"homophily\"], g[\"test_acc\"], label=model, alpha=0.8)\n",
        "plt.xlabel(\"Homophily ratio\")\n",
        "plt.ylabel(\"Test accuracy\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"output/experiments/real_homophily_vs_test_acc.png\", dpi=150)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "- Finalize dataset generation grid\n",
        "- Run the experiment loop\n",
        "- Record findings in the experiment log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save experiment log (once results exist)\n",
        "# out_path = \"output/experiments/gnn_failure_experiment_log.csv\"\n",
        "# pd.DataFrame(results).to_csv(out_path, index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
